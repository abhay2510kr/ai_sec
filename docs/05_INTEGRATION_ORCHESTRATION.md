# Integration and Orchestration Guide

## Overview
This guide covers the complete integration of AI models with traditional security tools, orchestration of multi-agent workflows, CI/CD integration, and building the complete AppSec platform.

---

## Table of Contents
1. [Architecture Overview](#architecture-overview)
2. [Agent Orchestration System](#agent-orchestration-system)
3. [Traditional Tool Integration](#traditional-tool-integration)
4. [CI/CD Pipeline Integration](#cicd-pipeline-integration)
5. [Web Dashboard](#web-dashboard)
6. [Workflow Automation](#workflow-automation)
7. [Complete Platform Deployment](#complete-platform-deployment)

---

## 1. Architecture Overview

### System Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Developer Workflows                       â”‚
â”‚  GitHub/GitLab â†’ CI/CD â†’ IDE Plugins â†’ CLI Tools â†’ Web UI       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     API Gateway (FastAPI)                        â”‚
â”‚  Authentication â”‚ Rate Limiting â”‚ Request Routing â”‚ Logging     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Orchestration Service                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ Task Queue   â”‚  â”‚ Job Schedulerâ”‚  â”‚Result Merger â”‚          â”‚
â”‚  â”‚ (Celery)     â”‚  â”‚              â”‚  â”‚              â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SAST Agent   â”‚  â”‚  SCA Agent   â”‚  â”‚  IaC Agent   â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚AI Model  â”‚ â”‚  â”‚ â”‚AI Model  â”‚ â”‚  â”‚ â”‚AI Model  â”‚ â”‚
â”‚ â”‚(CodeLlamaâ”‚ â”‚  â”‚ â”‚(CodeLlamaâ”‚ â”‚  â”‚ â”‚(CodeLlamaâ”‚ â”‚
â”‚ â”‚7B-SAST)  â”‚ â”‚  â”‚ â”‚7B-SCA)   â”‚ â”‚  â”‚ â”‚7B-IaC)   â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â”‚
â”‚      â”‚       â”‚  â”‚      â”‚       â”‚  â”‚      â”‚       â”‚
â”‚ â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚Traditionalâ”‚ â”‚  â”‚ â”‚Traditionalâ”‚ â”‚  â”‚ â”‚Traditionalâ”‚ â”‚
â”‚ â”‚Tools:     â”‚ â”‚  â”‚ â”‚Tools:     â”‚ â”‚  â”‚ â”‚Tools:     â”‚ â”‚
â”‚ â”‚Semgrep    â”‚ â”‚  â”‚ â”‚Trivy      â”‚ â”‚  â”‚ â”‚Checkov    â”‚ â”‚
â”‚ â”‚CodeQL     â”‚ â”‚  â”‚ â”‚OSV-Scannerâ”‚ â”‚  â”‚ â”‚tfsec      â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Container Agt â”‚  â”‚ API Agt      â”‚  â”‚ DAST Agt     â”‚
â”‚ + Trivy      â”‚  â”‚ + Custom     â”‚  â”‚ + OWASP ZAP  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Data Layer                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ PostgreSQL   â”‚  â”‚ Elasticsearchâ”‚  â”‚  Redis Cache â”‚          â”‚
â”‚  â”‚ (Findings DB)â”‚  â”‚ (Search Indexâ”‚  â”‚              â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Notification & Reporting                        â”‚
â”‚  Jira â”‚ GitHub Issues â”‚ Slack â”‚ Email â”‚ Webhooks â”‚ SARIF        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. Agent Orchestration System

### 2.1 Security Agent Base Class

```python
# File: services/orchestrator/agents/base_agent.py

from abc import ABC, abstractmethod
from typing import Dict, List, Optional
import httpx
import logging
from datetime import datetime

logger = logging.getLogger(__name__)

class SecurityAgent(ABC):
    """Base class for all security agents"""
    
    def __init__(self, name: str, ai_model_endpoint: str, traditional_tools: List[str]):
        self.name = name
        self.ai_model_endpoint = ai_model_endpoint
        self.traditional_tools = traditional_tools
        self.results_cache = {}
    
    @abstractmethod
    async def run_ai_analysis(self, target: Dict) -> Dict:
        """Run AI model analysis"""
        pass
    
    @abstractmethod
    async def run_traditional_tools(self, target: Dict) -> List[Dict]:
        """Run traditional security tools"""
        pass
    
    async def scan(self, target: Dict) -> Dict:
        """
        Run complete security scan:
        1. Run AI model analysis
        2. Run traditional tools
        3. Merge and validate results
        4. Return unified findings
        """
        start_time = datetime.now()
        
        logger.info(f"[{self.name}] Starting scan for target: {target.get('id', 'unknown')}")
        
        # Run AI and traditional tools in parallel
        import asyncio
        ai_task = asyncio.create_task(self.run_ai_analysis(target))
        tools_task = asyncio.create_task(self.run_traditional_tools(target))
        
        ai_results = await ai_task
        tool_results = await tools_task
        
        # Merge and validate
        merged_results = self.merge_results(ai_results, tool_results)
        validated_results = self.validate_findings(merged_results)
        
        duration = (datetime.now() - start_time).total_seconds()
        
        logger.info(f"[{self.name}] Scan complete in {duration:.2f}s. Found {len(validated_results)} findings.")
        
        return {
            'agent': self.name,
            'target': target,
            'findings': validated_results,
            'metadata': {
                'duration': duration,
                'ai_findings_count': len(ai_results.get('findings', [])),
                'tool_findings_count': sum(len(r.get('findings', [])) for r in tool_results),
                'timestamp': datetime.now().isoformat()
            }
        }
    
    def merge_results(self, ai_results: Dict, tool_results: List[Dict]) -> List[Dict]:
        """Merge AI and traditional tool results"""
        merged = []
        
        # Add AI findings
        for finding in ai_results.get('findings', []):
            finding['source'] = 'ai'
            finding['confidence'] = ai_results.get('confidence', 0.8)
            merged.append(finding)
        
        # Add tool findings
        for tool_result in tool_results:
            for finding in tool_result.get('findings', []):
                finding['source'] = tool_result.get('tool_name', 'unknown')
                finding['confidence'] = 1.0  # Traditional tools have high confidence
                merged.append(finding)
        
        return merged
    
    def validate_findings(self, findings: List[Dict]) -> List[Dict]:
        """
        Validate and enhance findings:
        - Cross-reference AI and tool findings
        - Deduplicate
        - Add confidence scores
        - Prioritize
        """
        validated = []
        seen_signatures = set()
        
        for finding in findings:
            # Create unique signature for deduplication
            signature = self.get_finding_signature(finding)
            
            if signature in seen_signatures:
                # Duplicate - merge confidence scores
                existing = next(f for f in validated if self.get_finding_signature(f) == signature)
                existing['confidence'] = max(existing['confidence'], finding['confidence'])
                existing['sources'] = existing.get('sources', []) + [finding['source']]
            else:
                seen_signatures.add(signature)
                finding['sources'] = [finding['source']]
                validated.append(finding)
        
        # Sort by severity and confidence
        validated.sort(key=lambda x: (
            self.severity_score(x.get('severity', 'LOW')),
            x.get('confidence', 0)
        ), reverse=True)
        
        return validated
    
    def get_finding_signature(self, finding: Dict) -> str:
        """Generate unique signature for finding"""
        return f"{finding.get('type')}:{finding.get('file')}:{finding.get('line')}"
    
    def severity_score(self, severity: str) -> int:
        """Convert severity to numeric score"""
        scores = {
            'CRITICAL': 4,
            'HIGH': 3,
            'MEDIUM': 2,
            'LOW': 1,
            'INFO': 0
        }
        return scores.get(severity.upper(), 0)
    
    async def call_ai_model(self, prompt: str, max_tokens: int = 512) -> str:
        """Call AI model endpoint"""
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(
                f"{self.ai_model_endpoint}/v1/completions",
                json={
                    "prompt": prompt,
                    "max_tokens": max_tokens,
                    "temperature": 0.1,
                    "top_p": 0.95
                }
            )
            response.raise_for_status()
            return response.json()['choices'][0]['text']
```

### 2.2 SAST Agent Implementation

```python
# File: services/orchestrator/agents/sast_agent.py

from .base_agent import SecurityAgent
import subprocess
import json
import re
from pathlib import Path

class SASTAgent(SecurityAgent):
    """Static Application Security Testing Agent"""
    
    def __init__(self):
        super().__init__(
            name="SAST",
            ai_model_endpoint="http://sast-model:8001",
            traditional_tools=["semgrep", "bandit"]
        )
    
    async def run_ai_analysis(self, target: Dict) -> Dict:
        """Run AI model analysis on code"""
        code_files = target.get('code_files', [])
        findings = []
        
        for file_info in code_files:
            file_path = file_info['path']
            code = file_info['content']
            language = file_info.get('language', 'python')
            
            # Create prompt
            prompt = f"""<s>[INST] You are a security code analyzer. Analyze the following code for vulnerabilities.

Language: {language}
Code:
```{language}
{code}
```

Identify any security vulnerabilities, provide the CWE type, severity, and explanation. [/INST]"""
            
            # Call AI model
            response = await self.call_ai_model(prompt)
            
            # Parse response
            parsed_findings = self.parse_ai_response(response, file_path)
            findings.extend(parsed_findings)
        
        return {
            'findings': findings,
            'confidence': 0.85
        }
    
    def parse_ai_response(self, response: str, file_path: str) -> List[Dict]:
        """Parse AI model response into structured findings"""
        findings = []
        
        # Extract CWE, severity, description
        # Simplified parsing - use more sophisticated NLP in production
        if "vulnerability" in response.lower():
            cwe_match = re.search(r'CWE-(\d+)', response)
            severity_match = re.search(r'Severity:\s*(CRITICAL|HIGH|MEDIUM|LOW)', response, re.IGNORECASE)
            
            finding = {
                'type': 'Security Vulnerability',
                'file': file_path,
                'cwe_id': cwe_match.group(0) if cwe_match else 'CWE-Unknown',
                'severity': severity_match.group(1).upper() if severity_match else 'MEDIUM',
                'description': response,
                'tool': 'AI-SAST'
            }
            findings.append(finding)
        
        return findings
    
    async def run_traditional_tools(self, target: Dict) -> List[Dict]:
        """Run Semgrep and Bandit"""
        results = []
        
        target_path = target.get('path', '.')
        
        # Run Semgrep
        semgrep_results = await self.run_semgrep(target_path)
        results.append(semgrep_results)
        
        # Run Bandit (Python only)
        if self.has_python_files(target_path):
            bandit_results = await self.run_bandit(target_path)
            results.append(bandit_results)
        
        return results
    
    async def run_semgrep(self, target_path: str) -> Dict:
        """Run Semgrep SAST scanner"""
        try:
            result = subprocess.run(
                ['semgrep', '--config=auto', '--json', target_path],
                capture_output=True,
                text=True,
                timeout=300
            )
            
            semgrep_output = json.loads(result.stdout)
            
            findings = []
            for item in semgrep_output.get('results', []):
                findings.append({
                    'type': item.get('check_id', 'Unknown'),
                    'file': item.get('path', ''),
                    'line': item.get('start', {}).get('line'),
                    'severity': item.get('extra', {}).get('severity', 'MEDIUM').upper(),
                    'description': item.get('extra', {}).get('message', ''),
                    'cwe_id': self.extract_cwe_from_semgrep(item),
                    'tool': 'Semgrep'
                })
            
            return {
                'tool_name': 'Semgrep',
                'findings': findings
            }
        
        except Exception as e:
            logger.error(f"Semgrep failed: {str(e)}")
            return {'tool_name': 'Semgrep', 'findings': []}
    
    async def run_bandit(self, target_path: str) -> Dict:
        """Run Bandit (Python security linter)"""
        try:
            result = subprocess.run(
                ['bandit', '-r', target_path, '-f', 'json'],
                capture_output=True,
                text=True,
                timeout=300
            )
            
            bandit_output = json.loads(result.stdout)
            
            findings = []
            for item in bandit_output.get('results', []):
                findings.append({
                    'type': item.get('test_id', 'Unknown'),
                    'file': item.get('filename', ''),
                    'line': item.get('line_number'),
                    'severity': item.get('issue_severity', 'MEDIUM').upper(),
                    'description': item.get('issue_text', ''),
                    'cwe_id': item.get('issue_cwe', {}).get('id', 'CWE-Unknown'),
                    'tool': 'Bandit'
                })
            
            return {
                'tool_name': 'Bandit',
                'findings': findings
            }
        
        except Exception as e:
            logger.error(f"Bandit failed: {str(e)}")
            return {'tool_name': 'Bandit', 'findings': []}
    
    def has_python_files(self, path: str) -> bool:
        """Check if path contains Python files"""
        return len(list(Path(path).rglob('*.py'))) > 0
    
    def extract_cwe_from_semgrep(self, item: Dict) -> str:
        """Extract CWE from Semgrep metadata"""
        metadata = item.get('extra', {}).get('metadata', {})
        cwe = metadata.get('cwe', [])
        return cwe[0] if cwe else 'CWE-Unknown'
```

### 2.3 SCA Agent Implementation

```python
# File: services/orchestrator/agents/sca_agent.py

from .base_agent import SecurityAgent
import subprocess
import json
from pathlib import Path

class SCAAgent(SecurityAgent):
    """Software Composition Analysis Agent"""
    
    def __init__(self):
        super().__init__(
            name="SCA",
            ai_model_endpoint="http://sca-model:8002",
            traditional_tools=["trivy", "osv-scanner"]
        )
    
    async def run_ai_analysis(self, target: Dict) -> Dict:
        """Run AI analysis on dependency manifests"""
        manifests = self.find_manifests(target.get('path', '.'))
        findings = []
        
        for manifest_path in manifests:
            with open(manifest_path) as f:
                manifest_content = f.read()
            
            manifest_type = self.detect_manifest_type(manifest_path)
            
            prompt = f"""<s>[INST] Analyze the following dependency manifest for vulnerable packages.

Manifest Type: {manifest_type}
Manifest:
```
{manifest_content}
```

Identify vulnerable dependencies, provide CVE IDs, severity scores, and remediation advice. [/INST]"""
            
            response = await self.call_ai_model(prompt)
            parsed_findings = self.parse_ai_response(response, str(manifest_path))
            findings.extend(parsed_findings)
        
        return {
            'findings': findings,
            'confidence': 0.90
        }
    
    async def run_traditional_tools(self, target: Dict) -> List[Dict]:
        """Run Trivy and OSV-Scanner"""
        results = []
        
        target_path = target.get('path', '.')
        
        # Run Trivy
        trivy_results = await self.run_trivy(target_path)
        results.append(trivy_results)
        
        # Run OSV-Scanner
        osv_results = await self.run_osv_scanner(target_path)
        results.append(osv_results)
        
        return results
    
    async def run_trivy(self, target_path: str) -> Dict:
        """Run Trivy for SCA"""
        try:
            result = subprocess.run(
                ['trivy', 'fs', '--format', 'json', target_path],
                capture_output=True,
                text=True,
                timeout=300
            )
            
            trivy_output = json.loads(result.stdout)
            
            findings = []
            for result_item in trivy_output.get('Results', []):
                for vuln in result_item.get('Vulnerabilities', []):
                    findings.append({
                        'type': 'Vulnerable Dependency',
                        'package': vuln.get('PkgName'),
                        'version': vuln.get('InstalledVersion'),
                        'cve_id': vuln.get('VulnerabilityID'),
                        'severity': vuln.get('Severity', 'MEDIUM').upper(),
                        'description': vuln.get('Description', ''),
                        'fixed_version': vuln.get('FixedVersion'),
                        'tool': 'Trivy'
                    })
            
            return {
                'tool_name': 'Trivy',
                'findings': findings
            }
        
        except Exception as e:
            logger.error(f"Trivy failed: {str(e)}")
            return {'tool_name': 'Trivy', 'findings': []}
    
    async def run_osv_scanner(self, target_path: str) -> Dict:
        """Run OSV-Scanner"""
        try:
            result = subprocess.run(
                ['osv-scanner', '-r', target_path, '--format', 'json'],
                capture_output=True,
                text=True,
                timeout=300
            )
            
            osv_output = json.loads(result.stdout)
            
            findings = []
            for result_item in osv_output.get('results', []):
                for package in result_item.get('packages', []):
                    for vuln in package.get('vulnerabilities', []):
                        findings.append({
                            'type': 'Vulnerable Dependency',
                            'package': package.get('package', {}).get('name'),
                            'version': package.get('package', {}).get('version'),
                            'cve_id': vuln.get('id'),
                            'severity': vuln.get('severity', 'MEDIUM').upper(),
                            'description': vuln.get('summary', ''),
                            'tool': 'OSV-Scanner'
                        })
            
            return {
                'tool_name': 'OSV-Scanner',
                'findings': findings
            }
        
        except Exception as e:
            logger.error(f"OSV-Scanner failed: {str(e)}")
            return {'tool_name': 'OSV-Scanner', 'findings': []}
    
    def find_manifests(self, path: str) -> List[Path]:
        """Find all dependency manifest files"""
        manifest_patterns = [
            'package.json',
            'requirements.txt',
            'Pipfile',
            'pom.xml',
            'build.gradle',
            'Gemfile',
            'go.mod',
            'Cargo.toml'
        ]
        
        manifests = []
        for pattern in manifest_patterns:
            manifests.extend(Path(path).rglob(pattern))
        
        return manifests
    
    def detect_manifest_type(self, manifest_path: Path) -> str:
        """Detect manifest type from filename"""
        name = manifest_path.name
        
        mapping = {
            'package.json': 'npm',
            'requirements.txt': 'pip',
            'Pipfile': 'pipenv',
            'pom.xml': 'maven',
            'build.gradle': 'gradle',
            'Gemfile': 'bundler',
            'go.mod': 'go',
            'Cargo.toml': 'cargo'
        }
        
        return mapping.get(name, 'unknown')
    
    def parse_ai_response(self, response: str, manifest_path: str) -> List[Dict]:
        """Parse AI response for vulnerable packages"""
        findings = []
        
        # Extract CVEs from response
        cve_pattern = r'(CVE-\d{4}-\d+)'
        cves = re.findall(cve_pattern, response)
        
        if cves:
            for cve in cves:
                findings.append({
                    'type': 'Vulnerable Dependency',
                    'file': manifest_path,
                    'cve_id': cve,
                    'severity': 'MEDIUM',  # Default, should be extracted from response
                    'description': response[:200],
                    'tool': 'AI-SCA'
                })
        
        return findings
```

### 2.4 Orchestrator Service

```python
# File: services/orchestrator/orchestrator.py

from celery import Celery, group
from typing import List, Dict
import asyncio
from agents.sast_agent import SASTAgent
from agents.sca_agent import SCAAgent
# Import other agents...

# Celery configuration
celery_app = Celery(
    'orchestrator',
    broker='redis://redis:6379/0',
    backend='redis://redis:6379/1'
)

celery_app.conf.update(
    task_serializer='json',
    accept_content=['json'],
    result_serializer='json',
    timezone='UTC',
    enable_utc=True,
)

class SecurityOrchestrator:
    """Orchestrates multiple security agents"""
    
    def __init__(self):
        self.agents = {
            'sast': SASTAgent(),
            'sca': SCAAgent(),
            # Initialize other agents
        }
    
    async def scan_repository(self, repo_config: Dict) -> Dict:
        """
        Run comprehensive security scan on repository
        Args:
            repo_config: {
                'repo_url': str,
                'branch': str,
                'scan_types': List[str],  # ['sast', 'sca', 'iac', ...]
                'exclude_paths': List[str]
            }
        """
        # Clone repository
        repo_path = await self.clone_repository(repo_config)
        
        # Prepare target
        target = {
            'id': repo_config.get('repo_url'),
            'path': repo_path,
            'code_files': await self.get_code_files(repo_path),
            'config': repo_config
        }
        
        # Determine which agents to run
        scan_types = repo_config.get('scan_types', ['sast', 'sca'])
        
        # Run agents in parallel
        tasks = []
        for scan_type in scan_types:
            if scan_type in self.agents:
                tasks.append(self.agents[scan_type].scan(target))
        
        agent_results = await asyncio.gather(*tasks)
        
        # Aggregate results
        aggregated = self.aggregate_results(agent_results)
        
        # Generate SARIF output
        sarif = self.generate_sarif(aggregated)
        
        # Store results in database
        await self.store_results(aggregated)
        
        # Send notifications
        await self.send_notifications(aggregated, repo_config)
        
        return {
            'scan_id': aggregated['scan_id'],
            'total_findings': len(aggregated['findings']),
            'critical': aggregated['summary']['critical'],
            'high': aggregated['summary']['high'],
            'medium': aggregated['summary']['medium'],
            'low': aggregated['summary']['low'],
            'sarif_path': sarif['path']
        }
    
    def aggregate_results(self, agent_results: List[Dict]) -> Dict:
        """Aggregate results from all agents"""
        all_findings = []
        
        for result in agent_results:
            all_findings.extend(result['findings'])
        
        # Deduplicate across agents
        deduplicated = self.deduplicate_findings(all_findings)
        
        # Calculate summary
        summary = {
            'critical': sum(1 for f in deduplicated if f['severity'] == 'CRITICAL'),
            'high': sum(1 for f in deduplicated if f['severity'] == 'HIGH'),
            'medium': sum(1 for f in deduplicated if f['severity'] == 'MEDIUM'),
            'low': sum(1 for f in deduplicated if f['severity'] == 'LOW')
        }
        
        return {
            'scan_id': self.generate_scan_id(),
            'timestamp': datetime.now().isoformat(),
            'findings': deduplicated,
            'summary': summary,
            'agent_metadata': [r['metadata'] for r in agent_results]
        }
    
    def generate_sarif(self, results: Dict) -> Dict:
        """Generate SARIF format output"""
        sarif = {
            "version": "2.1.0",
            "$schema": "https://json.schemastore.org/sarif-2.1.0.json",
            "runs": [
                {
                    "tool": {
                        "driver": {
                            "name": "AI AppSec Platform",
                            "version": "1.0.0"
                        }
                    },
                    "results": []
                }
            ]
        }
        
        for finding in results['findings']:
            sarif_result = {
                "ruleId": finding.get('cwe_id', 'Unknown'),
                "level": self.severity_to_sarif_level(finding['severity']),
                "message": {
                    "text": finding['description']
                },
                "locations": [
                    {
                        "physicalLocation": {
                            "artifactLocation": {
                                "uri": finding.get('file', '')
                            },
                            "region": {
                                "startLine": finding.get('line', 1)
                            }
                        }
                    }
                ]
            }
            sarif["runs"][0]["results"].append(sarif_result)
        
        # Save SARIF file
        sarif_path = f"/tmp/sarif/{results['scan_id']}.sarif"
        with open(sarif_path, 'w') as f:
            json.dump(sarif, f, indent=2)
        
        return {'path': sarif_path, 'content': sarif}
    
    def severity_to_sarif_level(self, severity: str) -> str:
        """Convert severity to SARIF level"""
        mapping = {
            'CRITICAL': 'error',
            'HIGH': 'error',
            'MEDIUM': 'warning',
            'LOW': 'note',
            'INFO': 'note'
        }
        return mapping.get(severity, 'warning')

# Celery tasks
@celery_app.task
def scan_repository_task(repo_config: Dict):
    """Celery task for repository scanning"""
    orchestrator = SecurityOrchestrator()
    loop = asyncio.get_event_loop()
    result = loop.run_until_complete(orchestrator.scan_repository(repo_config))
    return result
```

---

## 3. Traditional Tool Integration

### 3.1 Tool Wrapper Base Class

```python
# File: services/orchestrator/tools/base_tool.py

from abc import ABC, abstractmethod
import subprocess
import json
from typing import Dict, List

class SecurityTool(ABC):
    """Base class for security tool wrappers"""
    
    def __init__(self, name: str, command: str):
        self.name = name
        self.command = command
    
    @abstractmethod
    def run(self, target_path: str, **kwargs) -> Dict:
        """Run the security tool"""
        pass
    
    @abstractmethod
    def parse_output(self, output: str) -> List[Dict]:
        """Parse tool output into standard format"""
        pass
    
    def execute_command(self, args: List[str], timeout: int = 300) -> subprocess.CompletedProcess:
        """Execute command safely"""
        try:
            result = subprocess.run(
                [self.command] + args,
                capture_output=True,
                text=True,
                timeout=timeout
            )
            return result
        except subprocess.TimeoutExpired:
            raise Exception(f"{self.name} timed out after {timeout}s")
        except FileNotFoundError:
            raise Exception(f"{self.name} command not found: {self.command}")
```

### 3.2 Semgrep Wrapper

```python
# File: services/orchestrator/tools/semgrep_tool.py

from .base_tool import SecurityTool
import json

class SemgrepTool(SecurityTool):
    def __init__(self):
        super().__init__(name="Semgrep", command="semgrep")
    
    def run(self, target_path: str, **kwargs) -> Dict:
        config = kwargs.get('config', 'auto')
        
        args = [
            '--config', config,
            '--json',
            '--metrics', 'off',
            target_path
        ]
        
        result = self.execute_command(args)
        findings = self.parse_output(result.stdout)
        
        return {
            'tool': self.name,
            'findings': findings,
            'exit_code': result.returncode
        }
    
    def parse_output(self, output: str) -> List[Dict]:
        data = json.loads(output)
        
        findings = []
        for item in data.get('results', []):
            findings.append({
                'rule_id': item.get('check_id'),
                'file': item.get('path'),
                'line': item.get('start', {}).get('line'),
                'severity': item.get('extra', {}).get('severity', 'WARNING').upper(),
                'message': item.get('extra', {}).get('message'),
                'cwe': item.get('extra', {}).get('metadata', {}).get('cwe', []),
                'owasp': item.get('extra', {}).get('metadata', {}).get('owasp', [])
            })
        
        return findings
```

---

## 4. CI/CD Pipeline Integration

### 4.1 GitHub Actions Integration

```yaml
# File: .github/workflows/ai-appsec-scan.yml

name: AI AppSec Security Scan

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    - cron: '0 2 * * *'  # Daily at 2 AM

jobs:
  security-scan:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Run AI AppSec Scan
      uses: ai-appsec/scan-action@v1
      with:
        api_endpoint: ${{ secrets.APPSEC_API_ENDPOINT }}
        api_key: ${{ secrets.APPSEC_API_KEY }}
        scan_types: 'sast,sca,iac,container'
        fail_on_severity: 'critical,high'
        sarif_output: 'appsec-results.sarif'
    
    - name: Upload SARIF to GitHub Security
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: appsec-results.sarif
    
    - name: Comment PR with Results
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          const results = JSON.parse(fs.readFileSync('appsec-results.json'));
          
          const comment = `
          ## ðŸ”’ AI AppSec Scan Results
          
          **Critical:** ${results.summary.critical}
          **High:** ${results.summary.high}
          **Medium:** ${results.summary.medium}
          **Low:** ${results.summary.low}
          
          [View detailed results](${results.report_url})
          `;
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.name,
            body: comment
          });
```

### 4.2 GitLab CI Integration

```yaml
# File: .gitlab-ci.yml

stages:
  - security

ai-appsec-scan:
  stage: security
  image: ai-appsec/scanner:latest
  script:
    - |
      ai-appsec scan \
        --api-endpoint $APPSEC_API_ENDPOINT \
        --api-key $APPSEC_API_KEY \
        --scan-types sast,sca,iac \
        --fail-on-severity critical,high \
        --output appsec-results.json
  artifacts:
    reports:
      sast: appsec-results.sarif
    paths:
      - appsec-results.json
  allow_failure: true
```

### 4.3 Jenkins Pipeline Integration

```groovy
// File: Jenkinsfile

pipeline {
    agent any
    
    stages {
        stage('Checkout') {
            steps {
                checkout scm
            }
        }
        
        stage('AI AppSec Scan') {
            steps {
                script {
                    def scanResult = sh(
                        script: """
                            docker run --rm \
                                -v \$(pwd):/workspace \
                                ai-appsec/scanner:latest \
                                scan \
                                --api-endpoint ${env.APPSEC_API_ENDPOINT} \
                                --api-key ${env.APPSEC_API_KEY} \
                                --scan-types sast,sca \
                                --output /workspace/appsec-results.json
                        """,
                        returnStatus: true
                    )
                    
                    def results = readJSON file: 'appsec-results.json'
                    
                    echo "Critical: ${results.summary.critical}"
                    echo "High: ${results.summary.high}"
                    
                    if (results.summary.critical > 0) {
                        error("Critical vulnerabilities found!")
                    }
                }
            }
        }
    }
    
    post {
        always {
            archiveArtifacts artifacts: 'appsec-results.*', allowEmptyArchive: true
            publishHTML([
                reportDir: 'appsec-report',
                reportFiles: 'index.html',
                reportName: 'AI AppSec Report'
            ])
        }
    }
}
```

---

## 5. Web Dashboard

### 5.1 React Dashboard (Simplified Structure)

```jsx
// File: dashboard/src/App.jsx

import React from 'react';
import { BrowserRouter as Router, Routes, Route } from 'react-router-dom';
import Dashboard from './pages/Dashboard';
import Projects from './pages/Projects';
import Findings from './pages/Findings';
import Reports from './pages/Reports';

function App() {
  return (
    <Router>
      <div className="app">
        <Sidebar />
        <main className="content">
          <Routes>
            <Route path="/" element={<Dashboard />} />
            <Route path="/projects" element={<Projects />} />
            <Route path="/findings" element={<Findings />} />
            <Route path="/reports" element={<Reports />} />
          </Routes>
        </main>
      </div>
    </Router>
  );
}

export default App;
```

---

## 6. Workflow Automation

### 6.1 Automated Ticket Creation (Jira)

```python
# File: services/notifications/jira_integration.py

from jira import JIRA
from typing import Dict, List

class JiraIntegration:
    def __init__(self, url: str, username: str, api_token: str):
        self.jira = JIRA(
            server=url,
            basic_auth=(username, api_token)
        )
    
    def create_vulnerability_tickets(self, findings: List[Dict], project_key: str):
        """Create Jira tickets for each finding"""
        created_tickets = []
        
        for finding in findings:
            if finding['severity'] in ['CRITICAL', 'HIGH']:
                ticket = self.create_ticket(finding, project_key)
                created_tickets.append(ticket)
        
        return created_tickets
    
    def create_ticket(self, finding: Dict, project_key: str) -> Dict:
        """Create individual Jira ticket"""
        issue_dict = {
            'project': {'key': project_key},
            'summary': f"[{finding['severity']}] {finding['type']} in {finding['file']}",
            'description': self.format_description(finding),
            'issuetype': {'name': 'Bug'},
            'priority': {'name': self.severity_to_priority(finding['severity'])},
            'labels': ['security', 'ai-appsec', finding.get('cwe_id', '')]
        }
        
        new_issue = self.jira.create_issue(fields=issue_dict)
        
        return {
            'key': new_issue.key,
            'url': f"{self.jira.server_url}/browse/{new_issue.key}"
        }
    
    def format_description(self, finding: Dict) -> str:
        """Format finding as Jira description"""
        return f"""
*Vulnerability Type:* {finding['type']}
*Severity:* {finding['severity']}
*CWE:* {finding.get('cwe_id', 'N/A')}
*File:* {finding['file']}
*Line:* {finding.get('line', 'N/A')}

h3. Description
{finding['description']}

h3. Remediation
{finding.get('remediation', 'No remediation advice available')}

h3. Detection Source
{', '.join(finding.get('sources', []))}
        """
    
    def severity_to_priority(self, severity: str) -> str:
        mapping = {
            'CRITICAL': 'Highest',
            'HIGH': 'High',
            'MEDIUM': 'Medium',
            'LOW': 'Low'
        }
        return mapping.get(severity, 'Medium')
```

---

## 7. Complete Platform Deployment

### 7.1 Helm Chart

```yaml
# File: helm/ai-appsec/values.yaml

# Model replicas
models:
  sast:
    replicas: 2
    image: ai-appsec/sast-model:v1
  sca:
    replicas: 2
    image: ai-appsec/sca-model:v1
  iac:
    replicas: 1
    image: ai-appsec/iac-model:v1
  container:
    replicas: 1
    image: ai-appsec/container-model:v1

# API Gateway
apiGateway:
  replicas: 3
  image: ai-appsec/api-gateway:v1

# Orchestrator
orchestrator:
  replicas: 2
  image: ai-appsec/orchestrator:v1
  celeryWorkers: 4

# Dashboard
dashboard:
  replicas: 2
  image: ai-appsec/dashboard:v1

# Storage
postgresql:
  enabled: true
  auth:
    database: appsec_db
redis:
  enabled: true
elasticsearch:
  enabled: true
```

```bash
# Deploy complete platform
helm install ai-appsec ./helm/ai-appsec \
  --namespace ai-appsec \
  --create-namespace \
  --values custom-values.yaml
```

---

## Summary

âœ… **Multi-Agent Architecture**: Orchestrated AI + traditional tools
âœ… **CI/CD Integration**: GitHub Actions, GitLab CI, Jenkins
âœ… **Result Aggregation**: SARIF output, deduplication, prioritization
âœ… **Notifications**: Jira, Slack, email, webhooks
âœ… **Web Dashboard**: React-based UI for visualization
âœ… **Complete Platform**: Helm chart for full deployment

**Platform is now production-ready!** ðŸŽ‰

All documentation is complete:
1. âœ… [PROJECT_PLAN.md](PROJECT_PLAN.md)
2. âœ… [01_INFRASTRUCTURE_SETUP.md](docs/01_INFRASTRUCTURE_SETUP.md)
3. âœ… [02_DATA_PREPARATION.md](docs/02_DATA_PREPARATION.md)
4. âœ… [03_MODEL_TRAINING.md](docs/03_MODEL_TRAINING.md)
5. âœ… [04_MODEL_DEPLOYMENT.md](docs/04_MODEL_DEPLOYMENT.md)
6. âœ… [05_INTEGRATION_ORCHESTRATION.md](docs/05_INTEGRATION_ORCHESTRATION.md)
